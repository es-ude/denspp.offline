{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparing Training of Quantized and unquantized Model\n",
    "In this Notebook we compare the Training of different Models.\n",
    "All Models are Autoencoders, they differ in quantization. \n",
    "The 'normal' Model\n",
    "The 'creator' model\n",
    "The 'brevitas' model"
   ],
   "id": "49fdf77b3b3b613c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from elasticai.creator.nn.fixed_point.quantization import quantize\n",
    "\n",
    "from denspp.offline.yaml_handler import YamlConfigHandler\n",
    "from denspp.offline.dnn.dataset.autoencoder import prepare_training\n",
    "from denspp.offline.dnn.dnn_handler import ConfigMLPipeline, DefaultSettings_MLPipe\n",
    "from denspp.offline.dnn.pytorch_config_data import ConfigDataset, DefaultSettingsDataset\n",
    "from denspp.offline.dnn.pytorch_config_model import ConfigPytorch, DefaultSettingsTrainMSE\n",
    "from denspp.offline.dnn.plots.plot_dnn import results_training"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Load Configs\n",
    "yaml_handler = YamlConfigHandler(DefaultSettings_MLPipe, 'config', 'Config_DNN')\n",
    "dnn_handler = yaml_handler.get_class(ConfigMLPipeline)\n",
    "\n",
    "yaml_data = YamlConfigHandler(DefaultSettingsDataset, 'config', f'ConfigAE_Dataset')\n",
    "config_data = yaml_data.get_class(ConfigDataset)"
   ],
   "id": "ab0327372b5cc795",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Get Dataset\n",
    "dataset = prepare_training(settings=config_data, do_classification=False,\n",
    "                           mode_train_ae=0, noise_std=0.01)\n",
    "data_inference_test = dataset.__getitem__(4)"
   ],
   "id": "aa2d8bc763ee479d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing normal/quantized Model",
   "id": "c505193cc62ddca6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "48dc7a572020179e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "default_train = DefaultSettingsTrainMSE\n",
    "default_train.model_name = 'CompareDNN_Autoencoder_v1_Torch'\n",
    "yaml_nn = YamlConfigHandler(default_train, 'config', f'ConfigAE_Training')\n",
    "config_train = yaml_nn.get_class(ConfigPytorch)\n",
    "\n",
    "dnn_handler.do_plot  = False"
   ],
   "id": "ca186ca28c1c849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime, date\n",
    "from denspp.offline.dnn.pytorch_pipeline import do_train_autoencoder\n",
    "\n",
    "path4vhdl = f'vhdl/run_{date.today()}_{datetime.now().strftime(\"%H%M\")}'\n",
    "model_name_compare_wBN = ['CompareDNN_Autoencoder_v1_Torch', 'CompareDNN_Autoencoder_v1_Creator']\n",
    "model_name_compare_woBN = ['CompareDNN_Autoencoder_woBN_v1_Torch', 'CompareDNN_Autoencoder_woBN_v1_Creator']"
   ],
   "id": "8582d08ccd09f2b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_model_with_batchnorm = True\n",
    "if train_model_with_batchnorm:\n",
    "    used_models = model_name_compare_wBN\n",
    "else:\n",
    "    used_models = model_name_compare_woBN\n",
    "\n",
    "model_stats_torch = dict()\n",
    "config_train.model_name = used_models[0]\n",
    "used_model_torch = config_train.get_model()\n",
    "model_stats_torch['metrics'], model_stats_torch['data_result'], model_stats_torch['path2folder'] = do_train_autoencoder(\n",
    "    config_ml=dnn_handler, config_data=config_data, config_train=config_train,\n",
    "    used_dataset=dataset, used_model=used_model_torch, calc_custom_metrics=['dsnr_all', 'ptq_loss'], print_results=False, ptq_validation_do=True, ptq_quant_lvl=[12, 8]\n",
    ")"
   ],
   "id": "757a00040831028d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_stats_creator = dict()\n",
    "config_train.model_name = used_models[1]\n",
    "used_model_creator = config_train.get_model()\n",
    "model_stats_creator['metrics'], model_stats_creator['data_result'], model_stats_creator['path2folder'] = do_train_autoencoder(\n",
    "    config_ml=dnn_handler, config_data=config_data, config_train=config_train,\n",
    "    used_dataset=dataset, used_model=used_model_creator, calc_custom_metrics=['dsnr_all'], print_results=False\n",
    ")"
   ],
   "id": "216dca10179c0a27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting Results",
   "id": "280263f550e6a2fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "used_first_fold = [key for key in model_stats_torch[\"metrics\"].keys()][0]\n",
    "results_training(\n",
    "    path=model_stats_torch[\"path2folder\"], cl_dict=model_stats_torch[\"data_result\"]['cl_dict'], feat=model_stats_torch[\"data_result\"]['feat'],\n",
    "    yin=model_stats_torch[\"data_result\"]['input'], ypred=model_stats_torch[\"data_result\"]['pred'], ymean=dataset.get_mean_waveforms,\n",
    "    yclus=model_stats_torch[\"data_result\"]['valid_clus'], snr=model_stats_torch[\"metrics\"][used_first_fold]['dsnr_all'],\n",
    "    show_plot=dnn_handler.do_block\n",
    ")\n",
    "\n",
    "used_first_fold = [key for key in model_stats_creator[\"metrics\"].keys()][0]\n",
    "results_training(\n",
    "    path=model_stats_creator[\"path2folder\"], cl_dict=model_stats_creator[\"data_result\"]['cl_dict'], feat=model_stats_creator[\"data_result\"]['feat'],\n",
    "    yin=model_stats_creator[\"data_result\"]['input'], ypred=model_stats_creator[\"data_result\"]['pred'], ymean=dataset.get_mean_waveforms,\n",
    "    yclus=model_stats_creator[\"data_result\"]['valid_clus'], snr=model_stats_creator[\"metrics\"][used_first_fold]['dsnr_all'],\n",
    "    show_plot=dnn_handler.do_block\n",
    ")"
   ],
   "id": "33018e6f78e50b5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Comparison",
   "id": "7ac40704abfabc4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Extract metrics\n",
    "model_loss_train_torch = model_stats_torch['metrics']['fold_000']['loss_train']\n",
    "model_loss_valid_torch = model_stats_torch['metrics']['fold_000']['loss_valid']\n",
    "model_loss_valid_ptq = model_stats_torch['metrics']['fold_000']['ptq_loss']\n",
    "\n",
    "model_loss_train_creator = model_stats_creator['metrics']['fold_000']['loss_train']\n",
    "model_loss_valid_creator = model_stats_creator['metrics']['fold_000']['loss_valid']\n",
    "\n",
    "# --- Plotting\n",
    "fig, ax = plt.subplots()\n",
    "epochs_ite = np.array([idx+1 for idx in range(len(model_loss_train_torch))])\n",
    "ax.plot(epochs_ite, model_loss_train_torch, label='FP32, Training', linestyle='solid', marker='.', color='blue')\n",
    "ax.plot(epochs_ite, model_loss_valid_torch, label='FP32, Validation', linestyle='dotted', marker='.', color='blue')\n",
    "ax.plot(epochs_ite, model_loss_train_creator, label='QAT, Training', linestyle='solid', marker='v', color='red')\n",
    "ax.plot(epochs_ite, model_loss_valid_creator, label='QAT, Validation', linestyle='dotted', marker='v', color='red')\n",
    "ax.plot(epochs_ite, model_loss_valid_ptq, label='PTQ, Validation', linestyle='dotted', marker='s', color='green')\n",
    "\n",
    "font = {'size': 15}\n",
    "\n",
    "ax.grid()\n",
    "ax.legend(fontsize=font['size'])\n",
    "ax.margins(0)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Epoch', fontdict=font)\n",
    "ax.set_ylabel('Loss', fontdict=font)\n",
    "ax.set_title(label='Performance Comparison (FP vs. QAT (FxP) vs. PTQ (FxP))', fontdict=font)\n",
    "\n",
    "# Save Plot in runs Folder\n",
    "folder_name = f'../runs/comparisons'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "fig.savefig(f'{folder_name}/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_train_valid_loss.svg', format='svg')"
   ],
   "id": "5b5bc078ebe3a361",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing Inference",
   "id": "b0c4eb7785598ffb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Load model\n",
    "used_model_creator.eval()\n",
    "bit_config = used_model_creator.bit_config\n",
    "\n",
    "model_test_input = Tensor(data_inference_test['in'])\n",
    "model_test_input_quant = quantize(model_test_input, total_bits=bit_config[0], frac_bits=bit_config[1])\n",
    "print(f\"Quantized Input = {model_test_input}\")\n",
    "\n",
    "model_test_output = used_model_creator(model_test_input_quant)\n",
    "print(f\"Output = {model_test_output[0]}\")"
   ],
   "id": "73ee80cb6772ff8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fxpmath import Fxp\n",
    "\n",
    "def value_to_binary(x : Tensor, total_bits: int, frac_bits: int) -> str:\n",
    "    val = Fxp(float(x), signed=True, n_word=total_bits, n_frac=frac_bits)\n",
    "    return val.bin()\n",
    "    \n",
    "def tensor_to_vhdl_vector(X: Tensor, total_bits: int, frac_bits: int) -> str:\n",
    "    std_logic_vector : str = \"(\"\n",
    "    for idx, val in enumerate(X):\n",
    "        std_logic_vector += \"\\\"\"\n",
    "        std_logic_vector += value_to_binary(val, total_bits, frac_bits)\n",
    "        std_logic_vector += \"\\\",\"\n",
    "    std_logic_vector = std_logic_vector[:-1]\n",
    "    std_logic_vector += \")\"\n",
    "    return std_logic_vector\n",
    "\n",
    "print(f\"Input={tensor_to_vhdl_vector(model_test_input_quant, bit_config[0], bit_config[1])}\")\n",
    "print(model_test_output[0].flatten())\n",
    "print(f\"Output={tensor_to_vhdl_vector(model_test_output[0].flatten(), bit_config[0], bit_config[1])}={model_test_output[0].flatten()}\")"
   ],
   "id": "a96f52ef305c168d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Just first layer",
   "id": "b8ce125551b6116"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "q_input_layer_0 = quantize(model_test_input, total_bits=bit_config[0], frac_bits=bit_config[1])\n",
    "print(f\"Quantized Input = {q_input_layer_0}\")\n",
    "\n",
    "output_layer_0 = used_model_creator.forward_first_layer(q_input_layer_0)\n",
    "print(f\"Output = {output_layer_0}\")"
   ],
   "id": "12e23b6f331c4dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Input={tensor_to_vhdl_vector(q_input_layer_0, total_bits=bit_config[0], frac_bits=bit_config[1])}\")\n",
    "print(f\"Output={tensor_to_vhdl_vector(output_layer_0, total_bits=bit_config[0], frac_bits=bit_config[1])}\")"
   ],
   "id": "f2967547d84b97dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "670da665ec526958",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
